{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c30eac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c2d12862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments, pipeline, logging\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6ee8e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27a7da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your local JSON file\n",
    "file_path = 'chords_dataset_feb.json'\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset('json', data_files=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a0fd0a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, \"float16\")\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=compute_dtype, bnb_4bit_use_double_quant=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "30f0e12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['response', 'instruction'],\n",
       "        num_rows: 1400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "18467e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_template(example):\n",
    "    # You need to specify a key where the formatted string will be stored, for example, \"formatted\"\n",
    "    example[\"chat\"] = f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\\n{example['response']}\"\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46e4cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the chat_template function to each example in the dataset\n",
    "dataset = dataset.map(chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e8a27239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['response', 'instruction', 'chat'],\n",
       "        num_rows: 1400\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "669cd61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the 'train' subset further into training and validation sets\n",
    "dataset = dataset['train'].train_test_split(test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa07d805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['response', 'instruction', 'chat'],\n",
       "        num_rows: 1260\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['response', 'instruction', 'chat'],\n",
       "        num_rows: 140\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1ee03773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['response', 'instruction', 'chat'],\n",
       "    num_rows: 1260\n",
       "})"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2f420cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ### Instruction:\\nCould you list the notes in ...\n",
      "1    ### Instruction:\\nWhich notes are played toget...\n",
      "2    ### Instruction:\\nWhat sequence of notes compo...\n",
      "3    ### Instruction:\\nWhat sequence of notes compo...\n",
      "4    ### Instruction:\\nCould you list the notes in ...\n",
      "Name: chat, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'train' subset to a Pandas DataFrame\n",
    "df_train = dataset[\"train\"].to_pandas()\n",
    "\n",
    "# Print the \"chat\" column from the DataFrame\n",
    "print(df_train[\"chat\"].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24ceae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3867e1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "615c05de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "# Model\n",
    "base_model = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "#Fine-tune model name\n",
    "new_model = \"llama-2-7b-music-qa\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d19c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
